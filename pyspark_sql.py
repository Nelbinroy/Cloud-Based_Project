# -*- coding: utf-8 -*-
"""pyspark_sql.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_ooMjrvq5aOKMf8IM6b1weAUCaYL5kyb
"""

from pyspark.sql import SparkSession
from pyspark.ml.feature import VectorAssembler
from pyspark.ml.classification import LogisticRegression
from pyspark.ml import Pipeline

# Start Spark session
spark = SparkSession.builder.appName("Product Recommendation Classifier").getOrCreate()

# Load dataset
df = spark.read.csv("/content/Data.csv", header=True, inferSchema=True)

# Prepare data by dropping nulls and ensuring correct data types
# Use backticks to correctly reference columns with dots in their names
df = df.na.drop(subset=["`reviews.rating`", "`reviews.doRecommend`"])
df = df.withColumn("reviews_rating", df["`reviews.rating`"].cast("double"))
df = df.withColumn("reviews_numHelpful", df["`reviews.numHelpful`"].cast("integer"))
df = df.withColumn("label", df["`reviews.doRecommend`"].cast("integer"))

# Assemble features
assembler = VectorAssembler(inputCols=["reviews_rating", "reviews_numHelpful"], outputCol="features")

from pyspark.sql import SparkSession
from pyspark.ml.feature import VectorAssembler
from pyspark.ml.classification import LogisticRegression
from pyspark.ml import Pipeline
from pyspark.ml.evaluation import BinaryClassificationEvaluator

# Start Spark session
spark = SparkSession.builder.appName("Product Recommendation Classifier").getOrCreate()

# Load dataset
df = spark.read.csv("/content/Data.csv", header=True, inferSchema=True)

# Select and rename columns appropriately, ensuring we handle any nested naming issues
df = df.selectExpr("`reviews.rating` as reviews_rating", "`reviews.doRecommend` as reviews_doRecommend",
                   "`reviews.numHelpful` as reviews_numHelpful")

# Prepare data by dropping nulls and ensuring correct data types
df = df.na.drop(subset=["reviews_rating", "reviews_doRecommend"])
df = df.withColumn("reviews_rating", df["reviews_rating"].cast("double"))
df = df.withColumn("reviews_numHelpful", df["reviews_numHelpful"].cast("integer"))
df = df.withColumn("label", df["reviews_doRecommend"].cast("integer"))

# Assemble features
assembler = VectorAssembler(inputCols=["reviews_rating", "reviews_numHelpful"], outputCol="features")

# Configure the classifier
lr = LogisticRegression(featuresCol="features", labelCol="label")

# Create a Pipeline
pipeline = Pipeline(stages=[assembler, lr])

# Split the data into training and testing sets
train_data, test_data = df.randomSplit([0.7, 0.3])

# Fit the model
model = pipeline.fit(train_data)

# Predict on the test data
predictions = model.transform(test_data)

# Evaluate the model
evaluator = BinaryClassificationEvaluator()
accuracy = evaluator.evaluate(predictions)

print(f"Model Accuracy: {accuracy}")

from pyspark.ml.evaluation import MulticlassClassificationEvaluator
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# Assuming predictions are stored in a DataFrame 'predictions'
y_true = predictions.select("label").collect()
y_pred = predictions.select("prediction").collect()

# Generate confusion matrix
cm = confusion_matrix(y_true, y_pred)

# Plot confusion matrix
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot(cmap=plt.cm.Blues)
plt.title('Confusion Matrix')
plt.show()

from pyspark.sql import SparkSession
from pyspark.mllib.evaluation import BinaryClassificationMetrics

# Start Spark session
spark = SparkSession.builder.appName("Classification Metrics Example").getOrCreate()
sc = spark.sparkContext  # Get the SparkContext from the SparkSession

# Assuming you have some predictions from a model
# Example data (usually this will come from the output of a model)
results_collect = [(0.1, 1.0), (0.4, 0.0), (0.5, 1.0)]  # Sample prediction data
scoreAndLabels = sc.parallelize(results_collect)

# Instantiate metrics object
metrics = BinaryClassificationMetrics(scoreAndLabels)

# Compute the ROC statistics
print("Area under ROC = %s" % metrics.areaUnderROC)

# Clean up
spark.stop()  # Stop Spark session only when you are completely done

from pyspark.sql import SparkSession
from pyspark.mllib.evaluation import BinaryClassificationMetrics
from pyspark.mllib.linalg import Vectors
import matplotlib.pyplot as plt

# Start Spark session
spark = SparkSession.builder.appName("Manual ROC Example").getOrCreate()
sc = spark.sparkContext

# Example data
data = [(0.1, 0.0), (0.4, 1.0), (0.5, 0.0), (0.6, 1.0), (0.7, 1.0)]
rdd = sc.parallelize(data)

# Create a BinaryClassificationMetrics object
metrics = BinaryClassificationMetrics(rdd)

# Compute the Area Under the Curve
auc = metrics.areaUnderROC
print("Area under ROC = %s" % auc)

# Since `.roc()` is unavailable, manually calculate ROC points if necessary or skip plotting
# Normally, plotting would require FPR and TPR which are obtained from `.roc().collect()`

# Clean up
spark.stop()

import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc

# Example predicted probabilities and true labels
y_scores = [0.1, 0.4, 0.5, 0.6, 0.7]  # Probability predictions from your model
y_true = [0, 1, 0, 1, 1]              # Actual labels

# Calculate FPR, TPR, and threshold values
fpr, tpr, thresholds = roc_curve(y_true, y_scores)

# Calculate the AUC (Area under the ROC Curve)
roc_auc = auc(fpr, tpr)

# Plot the ROC curve
plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic')
plt.legend(loc="lower right")
plt.show()