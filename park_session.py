# -*- coding: utf-8 -*-
"""park_Session.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1F3l-tpMn1z4uSCVfHB2BYR-cr6JsRlzF
"""

pip install pyspark

from pyspark.sql import SparkSession
from pyspark.sql.functions import col
import matplotlib.pyplot as plt

# Initialize Spark Session
spark = SparkSession.builder.appName("Product Review Analysis").getOrCreate()

# Load data from CSV
df = spark.read.csv("/content/Data.csv", header=True, inferSchema=True)

# Data cleaning and preprocessing
# Use backticks to escape column names that include dots
df_cleaned = df.na.drop(subset=[ "`reviews.rating`", "`reviews.numHelpful`" ])  # Drop rows with null values in these columns
df_cleaned = df_cleaned.withColumn("reviews_rating", col("`reviews.rating`").cast("double"))  # Cast rating to double for calculations

# Diagnostic checks
print("Total number of rows: ", df_cleaned.count())
df_cleaned.show(5)
print("Unique ratings: ", df_cleaned.select("reviews_rating").distinct().collect())

# Visualize data: Ratings distribution
ratings_pd = df_cleaned.groupBy("reviews_rating").count().toPandas()  # Convert to Pandas DataFrame for plotting
ratings_pd.sort_values("reviews_rating", inplace=True)

plt.figure(figsize=(10, 5))
if not ratings_pd.empty:
    plt.bar(ratings_pd["reviews_rating"], ratings_pd["count"], color='blue')
    plt.xlabel("Rating")
    plt.ylabel("Count")
    plt.title("Distribution of Product Ratings")
    plt.xticks(ratings_pd["reviews_rating"].unique())  # Ensure x-ticks are set to unique rating values
else:
    plt.text(0.5, 0.5, 'No data available', horizontalalignment='center', verticalalignment='center', transform=plt.gca().transAxes)
plt.show()

# Save the Spark session
spark.stop()